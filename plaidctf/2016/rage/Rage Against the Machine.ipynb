{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rage Against the Machine\n",
      "========================\n",
      "\n",
      "In this challenge, a convolutional nerual network and the source code to the server it was attached to were given. In order to get the flag, an image had to be sent to the server and the classification accuracy of the 'good' node had to be greater than 0.99, or 99%. This notebook explains line by line what I was doing to solve this problem. Full script is 'networkbreaker.py' in this repo.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from brute import brute\n",
      "from pwn import *\n",
      "from hashlib import md5\n",
      "import numpy as np\n",
      "from scipy.ndimage import imread"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These were the libraries I used to solve the challenge. Brute is a simple brute forcing library that is easy to use. I'm partial to using it because I submitted a change to it not too long ago. Pwntools is a library centered around CTFs, and I use it for network connections later on. md5 from hashlib was used in the remote server source, so I used that to ensure I was generating the same strings. Numpy was used for image manipulation, and imread was used to read an image from a file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn = remote('localhost', 29281)  # server connection\n",
      "#conn = remote('40.117.46.42', 29281)  # ctf server connection\n",
      "salt = conn.recvn(12)  # get part of string from server"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the remote function from pwntools, I connected to the remote server and then received half of a string that was to be MD5 hashed. Using the string from the server, I had to add 6 more characters to generate a hash that started with 3 null bytes (0x00, 0x00, 0x00)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in brute(length=6, ramp=False):  # generated second part of string\n",
      "        if md5(salt+i).digest().startswith('\\x00\\x00\\x00'):  # get 3 nulls at beginning of hash\n",
      "                print('Broke md5 with ' + i)\n",
      "                conn.send(i)  # send second part of string\n",
      "                break  # and stop the brute forcing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm not priding myself with elegance on this one. I'm not much of a crypto person, so this was the easiest way I could think of to generate strings of length 6 to MD5 hash with the given part of the string. Sometimes it takes a few seconds, sometimes a few minutes. After it gets a hash that starts with three nulls, then it sends the string back to the server."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img = imread(\"plaid/wallpaper_20090122104623_19095694832.jpg\").astype(np.float32)  # plaid image via google image search\n",
      "img = img.transpose((2, 0, 1))  # Keras accepts (CxWxH) images, not the standard (WxHxC)\n",
      "img = img.copy(order='C')  # get data into contiguous, C-styled data block"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I got very lucky with this part. In some other tests, I tried to generate solid color images to pass through the neural network. They seemed to work with the Theano backend, but later hints suggested to use the TensorFlow backend for Keras. If you aren't a deep learning expert, don't worry about those. Since none of my own generated images worked, I went to my pile of datasets to test real images in the network. Using images from the Personal Contexts Dataset and the TUM Freiburg sequences, accuracies of 0 were returned from the neural network. Not really knowing what to try next beyond brute forcing pixels (which I also tried for a little bit), I figured my next best choice was to try a plaid image (PlaidCTF after all!). After downloading the first three hits for 'plaid' in a Google image search with exact dimensions of 320x240, one of them worked!\n",
      "\n",
      "Back to code: second line switches the dimensions of the image to be channels x width x height because of how Keras is anticipating an input image. Otherwise, the default image dimensions are width x height x channels (channels are red, green, and blue). After that, the data is put into a contiguous C-styled (as opposed to Fortran-styled) data block that can be transmitted in one go to the server."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Sending whole image\")\n",
      "conn.send(img)  # send image to server. it is already in format to send RGB channels in that order\n",
      "print(\"Receiving key?\")\n",
      "print(conn.recvline())  # get the key!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The entire image is sent and then I wait for the key to arrive. 250 points for us!\n",
      "\n",
      "In this GitHub repo, check out the other scripts I had for brute forcing image combinations (unsuccessfully) and the image I used to get the flag."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}